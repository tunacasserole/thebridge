# Token Usage Benchmark - Sample Output

This document shows the expected output from running `npm run benchmark:tokens`.

---

```
ðŸš€ Running Token Usage Benchmarks...

ðŸ“Š Benchmark Results:

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Simple Status Query
  Baseline:  450 tokens
  Optimized: 280 tokens
  Savings:   170 tokens (37.8%)
  Cost Saved: $0.0005

Long Conversation (20 messages)
  Baseline:  8,500 tokens
  Optimized: 5,200 tokens
  Savings:   3,300 tokens (38.8%)
  Cost Saved: $0.0099

Repeated Queries (10x same query)
  Baseline:  5,000 tokens
  Optimized: 500 tokens
  Savings:   4,500 tokens (90.0%)
  Cost Saved: $0.0135

Tool-Heavy Conversation
  Baseline:  1,800 tokens
  Optimized: 1,100 tokens
  Savings:   700 tokens (38.9%)
  Cost Saved: $0.0021

Large Context with Summarization
  Baseline:  3,200 tokens
  Optimized: 1,800 tokens
  Savings:   1,400 tokens (43.8%)
  Cost Saved: $0.0042

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ðŸ’° Overall Results:
  Total Baseline:  19,950 tokens
  Total Optimized: 12,880 tokens
  Total Savings:   7,070 tokens (35.4%)
  Cost Savings:    $0.0212 per cycle
  Monthly Savings: $21.20 (est. 1000 conversations)


ðŸ”„ Cache Performance Test:

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Total Queries:  100
  Cache Hits:     80 (80.0%)
  Cache Misses:   20
  Tokens Saved:   32,000
  Cost Saved:     $0.0960
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âœ… Performance Targets:
  Hit Rate Target:  >80% | Actual: 80.0% âœ“
  Tokens Saved:     >30K | Actual: 32,000 âœ“

âœ¨ Benchmarks complete!
```

---

## Understanding the Results

### Benchmark Scenarios

Each scenario tests a specific optimization strategy:

1. **Simple Status Query** (37.8% savings)
   - Optimization: Remove unnecessary tools
   - Strategy: Only load tools when needed

2. **Long Conversation** (38.8% savings)
   - Optimization: Truncate old messages
   - Strategy: Keep only recent context

3. **Repeated Queries** (90.0% savings)
   - Optimization: Response caching
   - Strategy: Cache common queries

4. **Tool-Heavy Conversation** (38.9% savings)
   - Optimization: Selective tool loading
   - Strategy: Load only necessary tools

5. **Large Context** (43.8% savings)
   - Optimization: Content summarization
   - Strategy: Compress verbose content

### Cost Calculations

**Pricing** (Claude Sonnet 4):
- Input: $3.00 per 1M tokens
- Output: $15.00 per 1M tokens

**Example Calculation**:
```
Simple Query Savings: 170 tokens
Cost Saved: 170 / 1,000,000 * $3.00 = $0.00051
```

**Monthly Projection**:
```
1,000 conversations/month * $0.0212 = $21.20/month
```

### Cache Performance

**Target Metrics**:
- Hit Rate: >80% âœ“
- Tokens Saved: >30K per 100 queries âœ“

**Interpretation**:
- 80% hit rate means 80 out of 100 queries are served from cache
- Each cache hit saves ~400 tokens on average
- Total savings: 80 * 400 = 32,000 tokens

### Performance Targets

All benchmarks validate against these targets:

âœ… Token reduction: 30-40% (Achieved: 35.4%)
âœ… Cache hit rate: >80% (Achieved: 80.0%)
âœ… Tokens saved: >30K (Achieved: 32,000)
âœ… Cost savings: Measurable (Achieved: $21.20/month)

---

## Running the Benchmarks

### Prerequisites

```bash
# Install dependencies
npm install

# Ensure lib/tokens is built
npx tsc --noEmit
```

### Run Benchmarks

```bash
# Run full benchmark suite
npm run benchmark:tokens

# Run with verbose output
DEBUG=* npm run benchmark:tokens
```

### Interpreting Results

**Good Results**:
- Token savings: 30-45%
- Cache hit rate: 75-90%
- Cost savings: $10-30/month per 1K conversations

**Poor Results** (needs investigation):
- Token savings: <25%
- Cache hit rate: <70%
- Cost savings: <$5/month per 1K conversations

**Factors Affecting Results**:
- Query patterns (repetition rate)
- Conversation length distribution
- Tool usage frequency
- Context window sizes

---

## Customizing Benchmarks

### Adjust Test Scenarios

Edit `tests/benchmarks/tokenUsage.ts`:

```typescript
// Modify scenario parameters
const messages = [
  { role: 'user', content: 'Your test query' },
  { role: 'assistant', content: 'Your test response' },
];

// Change conversation length
for (let i = 0; i < 50; i++) { // was 10
  // ... generate messages
}

// Adjust cache parameters
const cache = new ResponseCache(5000, 120); // 5K entries, 2hr TTL
```

### Add New Scenarios

```typescript
function benchmarkYourScenario(): BenchmarkResult {
  const messages = [/* your messages */];

  const baseline = countConversationTokens(messages, tools, systemPrompt);
  const optimized = /* your optimization */;

  return {
    scenario: 'Your Scenario Name',
    baseline: baseline.total,
    optimized: optimized.total,
    savings: baseline.total - optimized.total,
    savingsPercent: /* calculate % */,
    cost: /* calculate cost */,
  };
}

// Add to runTokenBenchmarks():
const results = [
  benchmarkSimpleQuery(),
  benchmarkYourScenario(), // <-- Add here
];
```

---

## Continuous Monitoring

### Production Metrics

Track these metrics in production:

1. **Average tokens per conversation**
   - Target: <5,000 tokens
   - Alert: >10,000 tokens

2. **Cache hit rate**
   - Target: >75%
   - Alert: <60%

3. **Budget overruns**
   - Target: <5% of conversations
   - Alert: >10%

4. **Cost per conversation**
   - Target: <$0.05
   - Alert: >$0.10

### Dashboard Queries

```typescript
// Average tokens per conversation
SELECT AVG(token_count) FROM conversations
WHERE created_at > NOW() - INTERVAL '24 hours';

// Cache hit rate
SELECT
  (cache_hits::float / (cache_hits + cache_misses)) * 100 as hit_rate
FROM cache_stats
WHERE date = CURRENT_DATE;

// Budget overruns
SELECT COUNT(*) FROM conversations
WHERE token_count > budget_limit;
```

---

## Troubleshooting

### Benchmark Failures

**"Token savings below expected"**:
- Check if optimizations are enabled
- Verify tool selection logic
- Review truncation algorithm

**"Cache hit rate too low"**:
- Increase TTL (cache expiration time)
- Review query normalization
- Check if test queries are realistic

**"Costs don't match"**:
- Verify pricing constants (may have changed)
- Check input/output token ratios
- Ensure cost calculation includes both input and output

### Performance Issues

**Benchmarks taking too long**:
- Reduce number of iterations
- Use smaller test datasets
- Profile with `console.time()`

**Memory issues**:
- Reduce cache size
- Clear cache between scenarios
- Use streaming for large conversations

---

## Next Steps

After running benchmarks:

1. **Review Results**: Compare against targets
2. **Identify Opportunities**: Look for low-performing scenarios
3. **Tune Parameters**: Adjust cache TTL, budget limits, etc.
4. **Deploy Changes**: Roll out optimizations to production
5. **Monitor**: Track production metrics
6. **Iterate**: Repeat benchmarks after changes

---

**Last Updated**: December 16, 2024
**Benchmark Version**: 1.0
